{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "from typing import Any, List\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "resources_dir = Path(os.path.abspath(\"\")).parent.parent / \"resources\"\n",
    "dss_dir = resources_dir / \"cad-models\"\n",
    "eval_dir = resources_dir / \"eval\"\n",
    "\n",
    "def process_num(value: Any):\n",
    "    if isinstance(value, list) or isinstance(value, set) or isinstance(value, tuple):\n",
    "        return [process_num(v) for v in value]\n",
    "    elif isinstance(value, float):\n",
    "        return round(round(value, 8), 4) # round by 8 to remove numerical inaccuracies, than by 4\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "def process(value: str, metadata: str, label: bool):\n",
    "    try:\n",
    "        if value != \"\":\n",
    "            value = ast.literal_eval(value)\n",
    "            value = process_num(value)\n",
    "            if isinstance(value, list) and len(value) > 0:\n",
    "                value = np.array(value).squeeze()\n",
    "                value[value == 0.] = 0.\n",
    "                value = value.tolist()\n",
    "                if len(value) == 1: \n",
    "                    value = value[0]\n",
    "            if 'sorted' in metadata:\n",
    "                value = sorted(value)\n",
    "            value = str(value)\n",
    "    except:\n",
    "        value = str(value)\n",
    "\n",
    "    if label:\n",
    "        if value.startswith(\"re\"):\n",
    "            re_value = value.split(\"re\")[1]\n",
    "        else:\n",
    "            re_value = re.escape(value)\n",
    "    else:\n",
    "        re_value = None\n",
    "\n",
    "    return value, re_value\n",
    "\n",
    "eval_metrics = []\n",
    "for ds_dir in sorted(dss_dir.iterdir()):\n",
    "    if not ds_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    # if ds_dir.name != 'industrial':\n",
    "    #     continue\n",
    "\n",
    "    abc_out_dir = ds_dir / \"processed\"\n",
    "    abc_eval_dir = eval_dir / ds_dir.name / \"processed\"\n",
    "\n",
    "    for sample in sorted(abc_out_dir.iterdir()):\n",
    "        with open(sample / \"input.txt\") as f:\n",
    "            text_batch = f.read()\n",
    "        text_batch = text_batch.split(\"\\n\")\n",
    "        \n",
    "        solution_file = sample / \"solution.txt\"\n",
    "        if not solution_file.is_file():\n",
    "            warnings.warn(\"%s - No solution developed yet\" % sample.name)\n",
    "            with open(solution_file, 'w') as f:\n",
    "                f.write(\"\".join([\"\\n\" for _ in range(len(text_batch) - 1)]))\n",
    "            # continue\n",
    "\n",
    "        metadata_file = sample / \"metadata.txt\"\n",
    "        metadata_batch = [\"\" for _ in range(len(text_batch))] \n",
    "        if metadata_file.is_file():\n",
    "            with open(metadata_file) as f:\n",
    "                metadata_subset = f.read().split(\"\\n\")\n",
    "            for i, val in enumerate(metadata_subset):\n",
    "                metadata_batch[i] = val\n",
    "\n",
    "        with open(solution_file) as f:\n",
    "            solution_batch = f.read()\n",
    "            solution_batch = solution_batch.split(\"\\n\")\n",
    "\n",
    "        assert len(solution_batch) == len(text_batch), sample\n",
    "        assert len(solution_batch) == len(metadata_batch), sample\n",
    "\n",
    "        for i, (text, solution, metadata) in enumerate(zip(text_batch, solution_batch, metadata_batch)):\n",
    "            response_dir = abc_eval_dir / sample.name / str(i)\n",
    "\n",
    "            eval_sample = {\n",
    "                'ds': ds_dir.name,\n",
    "                'id': sample.name,\n",
    "                \"question-idx\": i,\n",
    "                \"question\": text,\n",
    "                'label': solution\n",
    "            }\n",
    "\n",
    "            if not response_dir.is_dir():\n",
    "                warnings.warn(\"%s: %s - Not generated yet!\" % (sample.name, i))\n",
    "\n",
    "                eval_sample.update({\n",
    "                    'failed': True,\n",
    "                    'predicted': '',\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                eval_sample['failed'] = (response_dir / \"exception.txt\").is_file()\n",
    "\n",
    "                if not eval_sample['failed']:\n",
    "                    with open(response_dir / \"result.txt\") as f:\n",
    "                        eval_sample['predicted'] = f.read()\n",
    "                else:\n",
    "                    eval_sample['predicted'] = \"\"\n",
    "\n",
    "                try: \n",
    "                    predicted = ast.literal_eval(eval_sample['predicted'])\n",
    "                    if isinstance(predicted, tuple):\n",
    "                        eval_sample['predicted'] = str(list(predicted))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                eval_sample['predicted'], _ = process(eval_sample['predicted'], metadata=metadata, label=False)\n",
    " \n",
    "            eval_sample['label'], eval_sample['re_label'] = process(eval_sample['label'], metadata=metadata, label=True)\n",
    "            # if eval_sample['predicted'] != eval_sample['label']:\n",
    "            #     shutil.rmtree(response_dir)\n",
    "\n",
    "            eval_metrics.append(eval_sample)\n",
    "\n",
    "df = pd.DataFrame(eval_metrics)\n",
    "# df['correct'] = (df['predicted'] == df['label']) & ~df['failed']\n",
    "df['correct'] = (df.apply(lambda r: re.match(r['re_label'], r['predicted']) is not None, axis=1)) & ~df['failed']\n",
    "del df['re_label']\n",
    "\n",
    "if len(eval_sample['predicted']) > 100:\n",
    "    eval_sample['predicted'] = eval_sample['predicted'][:100] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(resources_dir / \"eval/eval-5-34of100.csv\")\n",
    "df_i = df.set_index(['ds', 'id', 'question-idx'])\n",
    "print('correct:', df_i['correct'].sum())\n",
    "print('questions:', (df_i['label'] != 'X').sum())\n",
    "df_i.style.set_properties(subset=['question'], **{'width': '600px'})\n",
    "df_i.to_csv(resources_dir / \"eval/eval-5-35of100.csv\")\n",
    "pd.options.display.max_rows = 111\n",
    "df_i\n",
    "# df[[\"ds\", 'id', 'question-idx', 'question']].to_csv('ds_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.groupby('id').sum()['correct'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for sample in abc_out_dir.iterdir():\n",
    "    with open(sample / \"input.txt\") as f:\n",
    "        text_batch = f.read()\n",
    "    text_batch = text_batch.split(\"\\n\")\n",
    "    \n",
    "    solution_file = sample / \"solution.txt\"\n",
    "    if not solution_file.is_file():\n",
    "        warnings.warn(\"%s - No solution developed yet\" % sample.name)\n",
    "        continue\n",
    "\n",
    "    with open(solution_file) as f:\n",
    "        solution_batch = f.read()\n",
    "        solution_batch = solution_batch.split(\"\\n\")\n",
    "\n",
    "    image = Image.open(sample / \"screenshot.png\")\n",
    "\n",
    "\n",
    "    title = \"\\n\".join([\"%s %s\" % (text, solution) for text, solution in zip(text_batch, solution_batch)])\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cad-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
